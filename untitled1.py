# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19xZHwaZr86gOshX2SxreeqZTm_kjdv2D
"""

import torch
from transformers import GPT2LMHeadModel, GPT2Tokenizer

# Cargar un modelo preentrenado de GPT-2 en español
model_name = "datificate/gpt2-small-spanish"  # GPT-2 preentrenado en español
model = GPT2LMHeadModel.from_pretrained(model_name)
tokenizer = GPT2Tokenizer.from_pretrained(model_name)

# Texto de entrada en español
input_text = "Me gusta mucho el futbol"

# Tokenizar el texto de entrada
input_ids = tokenizer.encode(input_text, return_tensors="pt")

# Generar texto adicional basado en la entrada
output = model.generate(
    input_ids,
    max_length=150,  # Ajusta la longitud del texto generado según sea necesario
    num_return_sequences=1,
    no_repeat_ngram_size=2,
    top_k=50,
    top_p=0.95,
    temperature=0.7
)

# Decodificar el texto generado en español
generated_text = tokenizer.decode(output[0], skip_special_tokens=True)

# Mostrar el texto generado en español
print("Texto generado:\n", generated_text)